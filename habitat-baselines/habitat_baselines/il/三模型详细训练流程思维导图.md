# IL模块三大核心模型详细训练流程思维导图

## 📋 概览

本文档详细描述了Habitat-Baselines IL模块中三个核心模型的具体训练流程、网络架构细节、预训练策略和输入输出规格。

---

## 🎯 模型1: MultitaskCNN (EQA-CNN-Pretrain)

### 🏗️ 网络架构详情

#### 编码器部分 (Encoder)
```
输入: RGB图像 (3, H, W)
├── Conv1: 3→64, kernel=7×7, stride=2, padding=3
│   ├── BatchNorm2d(64)
│   └── ReLU(inplace=True)
├── MaxPool2d: kernel=3×3, stride=2, padding=1
├── Conv2_x: ResNet基础块
│   ├── BasicBlock/Bottleneck × N层
│   └── 输出通道: 64
├── Conv3_x: ResNet基础块
│   ├── BasicBlock/Bottleneck × N层
│   └── 输出通道: 128
├── Conv4_x: ResNet基础块
│   ├── BasicBlock/Bottleneck × N层
│   └── 输出通道: 256
└── Conv5_x: ResNet基础块
    ├── BasicBlock/Bottleneck × N层
    └── 输出通道: 512
```

#### 特征瓶颈 (Feature Bottleneck)
```
输入: (512, H/32, W/32)
├── AdaptiveAvgPool2d(1) → (512, 1, 1)
├── Flatten → (512,)
├── Linear(512, 512)
├── ReLU
├── Dropout(0.5)
└── 输出: 512维特征向量
```

#### 解码器部分 (Decoder)
```
输入: 编码器各层特征 + 瓶颈特征
├── Deconv1: 512→256, kernel=4×4, stride=2, padding=1
│   ├── BatchNorm2d(256)
│   ├── ReLU
│   └── Skip Connection from Conv4_x
├── Deconv2: 256→128, kernel=4×4, stride=2, padding=1
│   ├── BatchNorm2d(128)
│   ├── ReLU
│   └── Skip Connection from Conv3_x
├── Deconv3: 128→64, kernel=4×4, stride=2, padding=1
│   ├── BatchNorm2d(64)
│   ├── ReLU
│   └── Skip Connection from Conv2_x
├── Deconv4: 64→32, kernel=4×4, stride=2, padding=1
│   ├── BatchNorm2d(32)
│   └── ReLU
└── Deconv5: 32→16, kernel=4×4, stride=2, padding=1
    ├── BatchNorm2d(16)
    └── ReLU
```

#### 多任务输出头 (Multi-task Heads)
```
共享特征: (16, H, W)
├── RGB重建头:
│   ├── Conv2d(16, 3, kernel=3×3, padding=1)
│   ├── Sigmoid激活
│   └── 输出: (3, H, W) RGB图像
├── 深度估计头:
│   ├── Conv2d(16, 1, kernel=3×3, padding=1)
│   ├── ReLU激活
│   └── 输出: (1, H, W) 深度图
└── 语义分割头:
    ├── Conv2d(16, num_classes, kernel=3×3, padding=1)
    └── 输出: (num_classes, H, W) 分割掩码
```

### 🎓 训练流程详情

#### 数据准备
```
数据集: EQACNNPretrainDataset
├── RGB图像: 原始彩色图像
├── 深度图: 对应的深度信息
├── 语义标签: 像素级分割标注
└── 数据增强:
    ├── RandomHorizontalFlip(p=0.5)
    ├── ColorJitter(brightness=0.2, contrast=0.2)
    ├── RandomRotation(degrees=10)
    └── Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
```

#### 损失函数设计
```
总损失 = λ₁×L_rgb + λ₂×L_depth + λ₃×L_semantic
├── RGB重建损失:
│   ├── SmoothL1Loss(reduction='mean')
│   └── 权重: λ₁ = 1.0
├── 深度估计损失:
│   ├── SmoothL1Loss(reduction='mean')
│   ├── 掩码处理: 忽略无效深度值
│   └── 权重: λ₂ = 1.0
└── 语义分割损失:
    ├── CrossEntropyLoss(ignore_index=255)
    ├── 类别权重平衡
    └── 权重: λ₃ = 1.0
```

#### 优化器配置
```
优化器: Adam
├── 学习率: 1e-4
├── 权重衰减: 1e-5
├── Beta参数: (0.9, 0.999)
├── 学习率调度:
│   ├── StepLR: 每30个epoch衰减0.1
│   └── 最小学习率: 1e-7
└── 梯度裁剪: max_norm=1.0
```

#### 训练超参数
```
训练配置:
├── Batch Size: 16
├── 总Epochs: 100
├── 验证频率: 每5个epoch
├── 保存频率: 每10个epoch
├── 早停策略: 验证损失20个epoch无改善
└── 设备: GPU (CUDA)
```

---

## 🤖 模型2: VQA模型 (VqaLstmCnnAttentionModel)

### 🏗️ 网络架构详情

#### 图像特征提取分支
```
输入: 图像序列 (T, 3, H, W)
├── CNN特征提取器:
│   ├── 预训练MultitaskCNN编码器
│   ├── 冻结前几层参数
│   └── 输出: (T, 512) 图像特征序列
├── 图像LSTM编码器:
│   ├── LSTM(input_size=512, hidden_size=512, num_layers=1)
│   ├── Dropout(0.5)
│   ├── 双向处理: bidirectional=True
│   └── 输出: (T, 1024) 双向隐藏状态
└── 图像特征投影:
    ├── Linear(1024, 512)
    ├── ReLU
    └── 输出: (T, 512) 标准化图像特征
```

#### 问题文本处理分支
```
输入: 问题文本 (Q_len,) token序列
├── 词嵌入层:
│   ├── Embedding(vocab_size, embed_dim=300)
│   ├── 预训练词向量: GloVe/Word2Vec
│   └── 输出: (Q_len, 300) 词嵌入
├── 问题LSTM编码器:
│   ├── LSTM(input_size=300, hidden_size=512, num_layers=2)
│   ├── Dropout(0.5)
│   ├── 双向处理: bidirectional=True
│   └── 输出: (Q_len, 1024) 双向隐藏状态
└── 问题特征投影:
    ├── Linear(1024, 512)
    ├── ReLU
    └── 输出: (Q_len, 512) 标准化问题特征
```

#### 注意力机制详情
```
多模态注意力计算:
├── 图像注意力:
│   ├── 输入: 图像特征(T, 512) + 问题最终状态(512)
│   ├── 注意力权重计算:
│   │   ├── e_t = MLP([img_feat_t; que_final])
│   │   ├── α_t = softmax(e_t)
│   │   └── 输出: (T,) 注意力权重
│   └── 加权特征: c_img = Σ(α_t × img_feat_t)
├── 问题注意力:
│   ├── 输入: 问题特征(Q_len, 512) + 图像最终状态(512)
│   ├── 注意力权重计算:
│   │   ├── f_i = MLP([que_feat_i; img_final])
│   │   ├── β_i = softmax(f_i)
│   │   └── 输出: (Q_len,) 注意力权重
│   └── 加权特征: c_que = Σ(β_i × que_feat_i)
└── 注意力MLP结构:
    ├── Linear(1024, 512)
    ├── ReLU
    ├── Dropout(0.3)
    ├── Linear(512, 256)
    ├── ReLU
    └── Linear(256, 1)
```

#### 特征融合与分类
```
多模态融合:
├── 特征拼接: [c_img; c_que] → (1024,)
├── 融合MLP:
│   ├── Linear(1024, 512)
│   ├── ReLU
│   ├── Dropout(0.5)
│   ├── Linear(512, 256)
│   ├── ReLU
│   └── Dropout(0.3)
├── 分类器:
│   ├── Linear(256, vocab_size)
│   └── 输出: (vocab_size,) 答案概率分布
└── 激活函数: LogSoftmax(dim=1)
```

### 🎓 训练流程详情

#### 数据准备
```
数据集: EQADataset
├── 图像序列: 导航过程中的RGB帧序列
├── 问题文本: 自然语言问题
├── 答案标签: 词汇表中的答案索引
├── 数据预处理:
│   ├── 图像: Resize(224, 224) + Normalize
│   ├── 文本: Tokenization + Padding
│   └── 序列长度: 最大20帧图像，最大15个词
└── 数据增强:
    ├── 图像: RandomCrop, ColorJitter
    └── 文本: 同义词替换(概率0.1)
```

#### 损失函数与优化
```
损失函数:
├── 主损失: CrossEntropyLoss
├── 标签平滑: label_smoothing=0.1
├── 类别权重: 根据答案频率计算
└── 正则化: L2权重衰减

优化器配置:
├── 优化器: Adam
├── 学习率: 5e-5
├── 权重衰减: 1e-4
├── 学习率调度:
│   ├── WarmupLinearSchedule
│   ├── Warmup steps: 1000
│   └── 总训练步数: 50000
└── 梯度累积: 4步累积
```

#### 评估指标
```
评估指标:
├── 准确率 (Accuracy):
│   ├── Top-1准确率
│   └── Top-5准确率
├── 平均排名 (Mean Rank):
│   ├── 正确答案在预测中的平均排名
│   └── 越小越好
├── 平均倒数排名 (MRR):
│   ├── Mean Reciprocal Rank
│   └── 越大越好
└── F1分数: 多类别F1-score
```

---

## 🧭 模型3: PACMAN导航模型 (NavPlannerControllerModel)

### 🏗️ 网络架构详情

#### 输入特征处理
```
多模态输入融合:
├── 图像特征 (512,):
│   ├── 来源: 预训练MultitaskCNN
│   ├── 处理: Linear(512, 256) + ReLU
│   └── 输出: (256,) 图像表示
├── 问题特征 (512,):
│   ├── 来源: 预训练VQA模型问题编码器
│   ├── 处理: Linear(512, 256) + ReLU
│   └── 输出: (256,) 问题表示
├── 历史动作 (action_dim,):
│   ├── One-hot编码: (num_actions,)
│   ├── 处理: Linear(num_actions, 64) + ReLU
│   └── 输出: (64,) 动作表示
├── 目标特征 (target_dim,):
│   ├── 目标物体特征或位置信息
│   ├── 处理: Linear(target_dim, 64) + ReLU
│   └── 输出: (64,) 目标表示
└── 特征拼接: [img; que; act; target] → (640,)
```

#### NavRnn核心组件
```
NavRnn结构 (可选LSTM/GRU):
├── 输入处理:
│   ├── Linear(640, 512)
│   ├── ReLU
│   └── Dropout(0.3)
├── RNN单元:
│   ├── LSTM版本:
│   │   ├── LSTM(512, 512, num_layers=2)
│   │   ├── 双向: bidirectional=False
│   │   └── Dropout: 0.5 (层间)
│   └── GRU版本:
│       ├── GRU(512, 512, num_layers=2)
│       ├── 双向: bidirectional=False
│       └── Dropout: 0.5 (层间)
├── 隐藏状态初始化:
│   ├── init_hidden()方法
│   ├── 零初始化或学习初始化
│   └── 形状: (num_layers, batch, hidden_size)
└── 输出处理:
    ├── 序列输出: (seq_len, batch, 512)
    ├── 最终隐藏状态: (num_layers, batch, 512)
    └── 单步输出: (batch, 512)
```

#### 分层控制架构
```
规划器模块 (Planner):
├── 输入: 融合特征 (640,)
├── NavRnn处理: LSTM(640→512)
├── 规划器头:
│   ├── Linear(512, 256)
│   ├── ReLU
│   ├── Dropout(0.4)
│   ├── Linear(256, num_high_actions)
│   └── 输出: 高级动作分布
└── 高级动作类型:
    ├── MOVE_FORWARD
    ├── TURN_LEFT
    ├── TURN_RIGHT
    ├── LOOK_UP
    ├── LOOK_DOWN
    └── STOP

控制器模块 (Controller):
├── 输入: 融合特征 + 规划器输出
├── 特征增强: [features; planner_output] → (640+num_high_actions,)
├── NavRnn处理: GRU(增强特征→512)
├── 控制器头:
│   ├── Linear(512, 256)
│   ├── ReLU
│   ├── Dropout(0.4)
│   ├── Linear(256, num_low_actions)
│   └── 输出: 低级控制信号
└── 低级动作类型:
    ├── 精确移动距离
    ├── 精确转向角度
    ├── 速度控制
    └── 停止条件
```

#### 解码器设计
```
动作解码器:
├── 规划器解码器:
│   ├── Linear(512, num_high_actions)
│   ├── LogSoftmax(dim=-1)
│   └── 输出: 高级动作概率
├── 控制器解码器:
│   ├── Linear(512, num_low_actions)
│   ├── LogSoftmax(dim=-1)
│   └── 输出: 低级动作概率
└── 联合解码:
    ├── 加权组合: α×planner + β×controller
    ├── 权重学习: α, β为可学习参数
    └── 最终输出: (num_actions,) 动作分数
```

### 🎓 训练流程详情

#### 数据准备
```
数据集: NavDataset
├── 导航轨迹: 专家演示序列
├── 状态序列: [s₁, s₂, ..., sₜ]
├── 动作序列: [a₁, a₂, ..., aₜ]
├── 奖励信号: 稀疏奖励(到达目标)
├── 序列处理:
│   ├── 最大序列长度: 500步
│   ├── 填充策略: 零填充
│   └── 掩码: 有效步数掩码
└── 数据增强:
    ├── 轨迹扰动: 添加噪声
    ├── 起始点随机化
    └── 目标点变化
```

#### 模仿学习策略
```
训练策略:
├── 行为克隆 (Behavior Cloning):
│   ├── 监督学习范式
│   ├── 最小化专家动作与预测动作差异
│   └── 损失: 交叉熵损失
├── DAgger (Dataset Aggregation):
│   ├── 迭代数据收集
│   ├── 模型预测 + 专家纠正
│   └── 逐步减少专家依赖
└── 分层训练:
    ├── 先训练规划器: 学习高级策略
    ├── 再训练控制器: 学习精确控制
    └── 联合微调: 端到端优化
```

#### 损失函数设计
```
分层损失函数:
├── 规划器损失:
│   ├── MaskedNLLCriterion
│   ├── 序列掩码: 忽略填充位置
│   ├── 权重: λ_planner = 1.0
│   └── 公式: L_p = -Σ mask_t × log(P(a_high_t|s_t))
├── 控制器损失:
│   ├── MaskedNLLCriterion
│   ├── 动作掩码: 忽略无效动作
│   ├── 权重: λ_controller = 1.0
│   └── 公式: L_c = -Σ mask_t × log(P(a_low_t|s_t, a_high_t))
├── 正则化项:
│   ├── L2权重衰减: 1e-5
│   ├── 熵正则化: 鼓励探索
│   └── KL散度: 与专家策略对齐
└── 总损失:
    L_total = λ_p×L_p + λ_c×L_c + λ_reg×L_reg
```

#### 优化器配置
```
优化器设置:
├── 优化器: Adam
├── 学习率调度:
│   ├── 规划器: 1e-4 → 1e-6 (指数衰减)
│   ├── 控制器: 5e-5 → 5e-7 (指数衰减)
│   └── 联合训练: 1e-5 (固定)
├── 梯度处理:
│   ├── 梯度裁剪: max_norm=5.0
│   ├── 梯度累积: 8步
│   └── 混合精度: FP16训练
└── 训练超参数:
    ├── Batch Size: 32
    ├── 序列长度: 最大500
    ├── 总训练步数: 100000
    └── 验证频率: 每1000步
```

#### 评估指标
```
导航评估指标:
├── 成功率 (Success Rate):
│   ├── 到达目标的轨迹比例
│   └── 阈值: 距离目标<0.5m
├── SPL (Success weighted by Path Length):
│   ├── 考虑路径效率的成功率
│   └── SPL = Success × (L_optimal / max(L_actual, L_optimal))
├── 导航效率:
│   ├── 平均步数
│   ├── 路径长度比
│   └── 时间效率
└── 动作分布:
    ├── 动作多样性
    ├── 停止准确性
    └── 转向精度
```

---

## 🔄 三模型联合训练流程

### 阶段1: MultitaskCNN预训练
```
预训练阶段 (20-30 epochs):
├── 目标: 学习通用视觉表示
├── 数据: RGB + 深度 + 语义标签
├── 输出: 预训练特征提取器
└── 检查点: multitask_cnn_pretrained.pth
```

### 阶段2: 独立模型训练
```
并行训练 (各30-50 epochs):
├── VQA模型训练:
│   ├── 加载: MultitaskCNN特征提取器
│   ├── 冻结: CNN前几层
│   ├── 训练: LSTM + 注意力 + 分类器
│   └── 输出: vqa_model_pretrained.pth
└── PACMAN模型训练:
    ├── 加载: MultitaskCNN特征提取器
    ├── 冻结: CNN特征提取部分
    ├── 训练: NavRnn + 分层控制器
    └── 输出: pacman_model_pretrained.pth
```

### 阶段3: 端到端微调
```
联合微调 (10-20 epochs):
├── 加载: 所有预训练模型
├── 学习率: 降低10倍
├── 训练: 完整EQA任务
├── 损失: 导航 + 问答联合损失
└── 输出: eqa_final_model.pth
```

---

## 📊 关键技术细节

### 内存优化
```
内存管理策略:
├── 梯度检查点: 减少中间激活存储
├── 混合精度: FP16 + FP32混合训练
├── 数据并行: 多GPU分布式训练
├── 序列截断: 动态序列长度
└── 批次大小调整: 根据GPU内存动态调整
```

### 训练稳定性
```
稳定性保证:
├── 梯度裁剪: 防止梯度爆炸
├── 权重初始化: Xavier/He初始化
├── 批归一化: 稳定训练过程
├── 学习率预热: 避免初期不稳定
└── 早停机制: 防止过拟合
```

### 模型保存与加载
```
检查点管理:
├── 模型状态: model.state_dict()
├── 优化器状态: optimizer.state_dict()
├── 学习率调度器: scheduler.state_dict()
├── 训练元信息: epoch, step, best_metric
└── 配置文件: 完整的超参数配置
```

---

## 🎯 总结

本思维导图详细描述了IL模块三大核心模型的完整训练流程，包括：

- **网络架构**: 每层的具体参数和连接方式
- **训练策略**: 分阶段训练和优化技巧
- **数据处理**: 输入输出格式和预处理流程
- **损失函数**: 多任务损失设计和权重平衡
- **评估指标**: 全面的性能评估体系
- **技术细节**: 内存优化和训练稳定性保证

这些详细信息为理解和复现EmbodiedQA系统提供了完整的技术指导。